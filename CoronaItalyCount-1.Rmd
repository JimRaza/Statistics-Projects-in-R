---
title: "Modelling of Coronavirus Data from Italy using Count Time Series Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

We present in this report a preliminary study  initiating a three part project into the modelling of  coronavirus data from Italy using count time series models. We will begin the series  with a univariate count time series model applied to the combinaed coronvirus data of all of Italy. We will then proceed to use multivariate models count time series models to several Italian regions, which will allow us to also study regional interactions. We will finish the series with a full spatio-temporal analysis of the data. Our aim in all three studies will be to model and predict the number of new infections.



## Generalized Linear Models for Count Time Series

In the present study we will use the tscount R package to model the coronavirus data as a univariate count time series with models of the form:


$$g(\lambda_t) = \beta_0 + \sum_{k=1}^{p} \beta_k \tilde{g}(Y_{t - i_k}) + \sum_{l=1}^q \alpha_l g(\lambda_{t - j_l}) +\mathbf{\eta}^T \mathbf{X}_t$$

Where $\{Y_t: \in \mathbb{N} \}$ denotes the count time series we wish to model.  $\mathbf{X}_t: t \in \mathbb{N}$ denotes an $r$ dimensional covariate vector, $\mathbf{X}_t = ( X_{t,1}, ..., X_{{t,r}} )^T$. We model the conditional mean,$E(Y_t \mid F_{t-1})$,  of the count time series by a process 
$\{\lambda_t : t \in \mathbb{N} \}$ such that $E(Y_t \mid F_{t-1}) = \lambda_t$ . $F_t$ denotes the history of the joint process $\{Y_t, \lambda_t, \mathbf{X}_{t+1} :t \in \mathbb{N} \}$.

$g : R^+ \rightarrow \mathbb{R}$  $\tilde{g}: N_0 \rightarrow \mathbb{R}$ are a link function and transformation function, respectively. The response and the mean values are regressed $p$ and $q$ time steps, respectively. In the language of generalized linear models $\nu_t = g(\lambda_t)$ is called the linear predictor.

We consider two special cases of the above model. If the distribution of $Y_t$ is Poisson and both the link and transformation function are identities we obain the INGARCH model:

$$ \lambda_t = \beta_0 + \sum_{k=1}^{p} \beta_k (Y_{t - i_k}) + \sum_{l=1}^q \alpha_l \lambda_{t - j_l} $$
The covariate vector $\mathbf{\eta} = 0$ therefore no covariate effects are included in the above model.

If we consider a link function of the form $g(x) = \log (x)$ and transformation function of the form $\tilde{g}(x) = \log(x+1)$ then we obtain the log-linear model:


$$ \nu_t = \log(\lambda_t) = \beta_0 + \sum_{k=1}^{p} \beta_k \log(Y_{t - i_k} + 1) + \sum_{l=1}^q \alpha_l \nu_{t - j_l} $$

We may further divide the above models into categories depending on whether the conditional mean is a Poisson process:$Y_t \mid F_{t-1} \text \sim  \text{Poisson}(\lambda_t)$ or a negative binomial process $Y_t \mid F_{t-1} \text \sim  \text{NegBin}(\lambda_t, \phi)$

$\text{VAR}(Y_t \mid F_{t-1}) = \text{E}(Y_t \mid F_{t-1}) = \lambda_t$ for a conditional Poisson response. For a negative binomial response
$\text{VAR}(Y_t \mid F_{t-1}) = \lambda_t + \lambda_t^{2} / \phi$, where $\phi$ is the dispersion parameter $\phi \in (0, \mathbb{inf})$.

#### Interventions

Interventions are included in the model as covariates and are denoted by $\delta_m$ for the $m$-th intervention.

$$ g(\lambda_t) = \beta_0 + \sum_{k=1}^{p} \beta_k \tilde{g}(Y_{t - i_k}) + \sum_{l=1}^q \alpha_l g(\lambda_{t - j_l}) + \mathbf{ \eta}^T \mathbf{X}_t 
+ \sum_{m=1}^s \omega_m \delta_{m}^{t - \tau_m}    \mathbb{1} (t \geq \tau_m)$$

For a spiky intervention $\delta=0$, for an exponentially decading change in location $\delta \in (0,1)$ and for permanent level shift $\delta=1$.

The model parameters are estimated in the tscount package using a quasi-maximum likelihood approach and BGFS based opmtimization routines.

## Data

Using the dpylr package the data for all the seperate regions of Italy are combined into one set of time series. 

```{r}
library("tidyverse")
library("lubridate")
finalpdf <- read_csv("covid19_italy_region3.csv") %>%
select( Date, HospitalizedPatients:TestsPerformed) %>%
mutate( Date = dmy_hm(Date)) %>%
mutate(Date = date(Date)) %>%
group_by( Date)  %>%
summarize_all(sum)
finalpdf
```

The variable in the dataframe we want to predict is the number of new infections, NewPositiveCases. Plotting this variable against time we obtain the following graph:
```{r}
finalPos = finalpdf$NewPositiveCases
plot(finalPos)
```

## Data Analysis

We observe in the previous plot that the number of new infections is increasing with time, therefore the data is not stationary. We can deal with this nonstationarity by adding a linear trend as a covariate when we build our model. We condition the present response variable on the immediately preceding response variable and  also add a seasonal effect on the mean of 5 days, which is just less than a week,

First we fit an INGARCH mode to the data (with a link function that is the identity). We use the number of people confined to the home as a covariate and we also add a linear trend.

```{r}
library("tscount")
regressors <- cbind(finalpdf$HomeConfinement, linearTrend = seq(along = finalPos))
final_pois <- tsglm(finalPos, model = list(past_obs = c(1), past_mean = 5), link= "identity", distr = "poisson", xreg = regressors)
```
This model has not found any serial dependence in the data, which cannot be correct. Let us view the autocorrelation function of the residuals:

```{r}
acf(residuals(final_pois), main = "ACF of response residuals")
```

This autocorrelation function confirms that there are strong serial correlations in the residuals and that the model has failed to capture any serial dependence in the original data, In our next attempt we use  the log link function to give us a loglinar model and view its autocorrelation function:

```{r}

final_pois <- tsglm(finalPos, model = list(past_obs = c(1), past_mean = 5), link= "log", distr = "poisson", xreg = regressors)
```


The autocorrelations of the residuals are now very close to white noise, indicating that the model has succesfuly captured the (linear) serial correlation of the original time series:


```{r}
acf(residuals(final_pois), main = "ACF of response residuals")
```

Additionally, we fit a loglinear model with a negative binomial conditional mean to our data:

```{r}

final_nbin <- tsglm(finalPos, model = list(past_obs = c(1), past_mean = 5), link = "log", distr = "nbinom", xreg = regressors)
```

### Model Diagnostics
The tscount package provides several tools with which to assess model fits. These diagnostics a re based on the predictive performance of the fit models.  We apply these to our two models.

The marginal calibration is the the difference of the average predictive c.d.f. and the emprical c.d.f. of the observations. For an ideal predictive model the marginal calibration should be zero. We can observe in the following graph that while neither model is ideal the marginal calibration of the negative binomial model is significantly better:

```{r}
marcal(final_pois, main = "Marginal calibration")
lines(marcal(final_nbin, plot = FALSE), lty = "dashed")                                  
legend("bottomright", legend = c("Pois", "NegBin"), lwd = 1, lty = c("solid", "dashed"))
```

A model whose predictive distribution is identical to the data generating distribution (i.e. an ideal predictive model) would give a Probability Integral Transform (PIT) that is completely flat. Of course with noisy and finite data that ideal is unobtainable in general and we would expect even an ideal model to give a PIT distribution that only  approximates a uniform one. The closer the PIT of a mdoel to a uniform distribution the better its fit to the data.

```{r}
pit(final_pois, ylim = c(0, 1.5), main = "PIT Poisson")

```
The PIT for the Poisson model indicates that this model's predictive perfomance is very poor.
```{r}
pit(final_nbin, ylim = c(0, 1.5), main = "PIT Negative Binomial")

```

The PIT for the negative bionomial distribution looks much better even if not ideal. 


```{r}
rbind(Poisson = scoring(final_pois), NegBin = scoring(final_nbin))
```

Another way to assess the predictive performances are proper scoring rules. Various scores are presented above for both models. Most of the proper scores strongly favour the negative binomial model over the Poisson model. The normaized square error score (normsq) of an ideal model is one. It can be observed that the normsq for the Poisson model is far from ideal while for the negative binomial it is reasonably good, in agreement with other diagnostics.


We present a summary of the best model we have found so far:
```{r}
summary(final_nbin)

```

The final model our analysis has arrived at has the following form:

$$ \lambda_t = 2.74 + 0.12 Y_{t-1} + 0.323 \lambda_{t-5}  + 0.109t$$ 
The mean has a weak but unmistakable dependence on the respone variable for the previous day. We can also detect an almost weekly seasonal effect. As expected a trend is present. However, the covariate no influence on the number of new infections. However, this may be because it has linear trend effect that is being captured by the explicitly included trend covariate. Curiously, the overdispersion parameter is  small. This seems unusual given that the Poisson based model performed so poorly.  Further investigation of both issues is needed.

### Intervention Analysis

The Italian government ordered a national lockdown  on the 9th of March. It would be interesting to see if we can find evidence of an effect of this lockdown on the number new infections. The effect of a lockdown is believed to take 7-14 days typically so we cannot pin down an exact date when we expect to observe it.  Therefore we use tscounts interv_multiple function to look for the type and timing of the intervention.
```{r}
interv_multiple(final_nbin)

```

No effect of the 9th March lockdown is detected up until the 28th of March. This is an agreement with the generally held view that no flattening behaviour in the number of new infections was observed in Italy till this date. However, it could also be because the effect of the lockdown takes a form not included in the tscount package.
  

## Discussion

We developed a count time series model that gives a reasonable fit to the data, though there is room for improvement. We found that the number of infections depends on the previous days but no days prior that, There was in addition a near-weekly seasonal dependence on the mean. This seasonal effect may be the result either of weekly cycles in human behaviour at testing labs  or the intrinsic dynamics of the spread of the virus.  One avenue for model improvement is the inclusion of a harmonic component with a weekly period as a regressor. No effect from the 9th March lockdown imposed by the Italian government could be detected in the data.



